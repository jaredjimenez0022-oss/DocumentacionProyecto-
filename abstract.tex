%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%		~~~~ Abstract ~~~~
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

\noindent
La interacción humano-computadora ha evolucionado hacia sistemas multimodales capaces de procesar simultáneamente voz, imagen y texto. En contextos educativos y empresariales, existe la necesidad de asistentes inteligentes que no solo ejecuten comandos, sino que también comprendan el estado emocional del usuario y proporcionen análisis predictivos en tiempo real.

Este proyecto presenta 
\textbf{Jarvis TEC}, un asistente inteligente desarrollado con arquitectura de microservicios que integra reconocimiento facial con detección de emociones (DeepFace), procesamiento de voz mediante Speech-to-Text (Azure Cognitive Services), y un conjunto de 10 modelos de Machine Learning especializados en predicción y clasificación. El sistema utiliza técnicas de ensemble learning, principalmente Random Forest y Gradient Boosting, para tareas que van desde predicción financiera (Bitcoin, S&P 500) hasta análisis médico (cirrosis hepática, IMC) y social (predicción de crímenes urbanos).

Los resultados experimentales demuestran que el sistema alcanza una precisión promedio del 85\% en clasificación de emociones y R² superior a 0.75 en tareas de regresión. La arquitectura basada en FastAPI y React permite procesamiento en tiempo real con latencia inferior a 500ms para la mayoría de las predicciones.

Este trabajo contribuye al campo de asistentes virtuales multimodales aplicados en entornos educativos, demostrando la viabilidad de integrar múltiples modelos especializados en una interfaz unificada y accesible.

\end{abstract}
